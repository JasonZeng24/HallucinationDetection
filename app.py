import streamlit as st
import torch
from transformers import AutoTokenizer, AutoModelForSequenceClassification
import numpy as np
import pandas as pd
import os
from huggingface_hub import hf_hub_download # ä¿æŒå¯¼å…¥ï¼Œä»¥å¤‡ä¸æ—¶ä¹‹éœ€

# ========================================================================
# --- é…ç½®ä¿¡æ¯ ---
# ========================================================================
# ğŸš¨ å‡è®¾ä½ çš„ Hugging Face ä»“åº“æ˜¯æ ‡å‡†çš„ Transformer æ¨¡å‹æ ¼å¼ï¼ˆåŒ…å« config.json, pytorch_model.bin ç­‰ï¼‰
# å¦‚æœä½ çš„æ¨¡å‹æ–‡ä»¶ä¸æ˜¯æ ‡å‡†çš„ï¼Œä½ éœ€è¦æ‰‹åŠ¨ä¸‹è½½æ‰€æœ‰æ–‡ä»¶å¹¶åŠ è½½
HF_REPO_ID = "Jasonzeng/EduCheck" # æ›¿æ¢ä¸ºä½ çš„å®é™…ä»“åº“ID

# --- æ ‡ç­¾æ˜ å°„ ---
LABEL_MAPPING = {
    0: "Non-Hallucination (Safe) âœ…",
    1: "Hallucination Detected ğŸš¨"
}
CONFIDENCE_LABELS = ["Non-Hallucination", "Hallucination"]

# ========================================================================
# --- æ¨¡å‹åŠ è½½å‡½æ•° (ä½¿ç”¨ Streamlit ç¼“å­˜) ---
# ========================================================================

@st.cache_resource
def load_model_and_tokenizer():
    """
    åŠ è½½æ¨¡å‹å’Œåˆ†è¯å™¨ã€‚ä½¿ç”¨ @st.cache_resource ç¡®ä¿åªåœ¨ Streamlit å¯åŠ¨æ—¶è¿è¡Œä¸€æ¬¡ã€‚
    Hugging Face's from_pretrained() ä¼šè‡ªåŠ¨å¤„ç†ä¸‹è½½å’Œç¼“å­˜ã€‚
    """
    st.info(f"æ­£åœ¨ä» Hugging Face Hub åŠ è½½æ¨¡å‹: {HF_REPO_ID}...")
    try:
        # 1. åŠ è½½åˆ†è¯å™¨
        tokenizer = AutoTokenizer.from_pretrained(HF_REPO_ID)
        
        # 2. åŠ è½½æ¨¡å‹
        # ç”±äºæ¨¡å‹æ–‡ä»¶å¯èƒ½è¾ƒå¤§ï¼Œè¿™å°†åœ¨ Streamlit Cloud é¦–æ¬¡éƒ¨ç½²æ—¶è‡ªåŠ¨ä¸‹è½½
        model = AutoModelForSequenceClassification.from_pretrained(HF_REPO_ID)
        
        st.success("æ¨¡å‹å’Œåˆ†è¯å™¨åŠ è½½æˆåŠŸï¼")
        return tokenizer, model
        
    except Exception as e:
        st.error(f"âŒ åŠ è½½æ¨¡å‹æˆ–åˆ†è¯å™¨å¤±è´¥ã€‚é”™è¯¯ä¿¡æ¯: {e}")
        st.warning("è¯·æ£€æŸ¥ Hugging Face ä»“åº“ ID æ˜¯å¦æ­£ç¡®ï¼Œå¹¶ç¡®è®¤å…¶åŒ…å«å®Œæ•´çš„ 'config.json'ã€'tokenizer_config.json' å’Œæ¨¡å‹æƒé‡æ–‡ä»¶ (å¦‚ 'pytorch_model.bin')ã€‚")
        return None, None

# --- åœ¨ Streamlit åº”ç”¨å¯åŠ¨æ—¶åŠ è½½æ¨¡å‹ ---
tokenizer_real, model_real = load_model_and_tokenizer()

# ========================================================================
# --- é¢„æµ‹å‡½æ•° ---
# ========================================================================

def predict_hallucination(input_text: str, tokenizer, model):
    """ä½¿ç”¨åŠ è½½çš„æ¨¡å‹è¿›è¡Œå¹»è§‰é¢„æµ‹ã€‚"""
    if model is None or tokenizer is None:
        st.error("é¢„æµ‹å¤±è´¥ï¼šæ¨¡å‹æœªåŠ è½½ã€‚è¯·æ£€æŸ¥æ¨¡å‹æ–‡ä»¶ã€‚")
        return None, None, None

    # è®¾ç½®æ¨¡å‹ä¸ºè¯„ä¼°æ¨¡å¼
    model.eval()
    
    # ç¼–ç è¾“å…¥æ–‡æœ¬
    inputs = tokenizer(input_text, 
                       padding="max_length", 
                       truncation=True, 
                       max_length=128, 
                       return_tensors="pt")
    
    # ç¦ç”¨æ¢¯åº¦è®¡ç®—ä»¥èŠ‚çœå†…å­˜å¹¶åŠ é€Ÿæ¨ç†
    with torch.no_grad():
        outputs = model(**inputs)
        
    # è®¡ç®—æ¦‚ç‡
    probabilities = torch.softmax(outputs.logits, dim=1).squeeze().numpy()
    
    # è·å–é¢„æµ‹ç±»åˆ«IDå’Œç½®ä¿¡åº¦
    predicted_class_id = np.argmax(probabilities).item()
    confidence = probabilities[predicted_class_id].item()
    
    return predicted_class_id, confidence, probabilities

# =======================================================
# --- Streamlit UI ç»„ä»¶ ---
# =======================================================

st.set_page_config(layout="wide", page_title="EduCheck: AI Content Safety")

st.title("ğŸ›¡ï¸ EduCheck: AI æ•™è‚²å†…å®¹å®‰å…¨æ£€æµ‹å™¨")
st.markdown("---")

st.subheader("è¶…è¶Šäº‹å®æ ¸æŸ¥ï¼šæ£€æµ‹æ•™å­¦æ³•å’Œæ¦‚å¿µç¼ºé™·")
st.info("è¯¥å·¥å…·éªŒè¯ AI ç”Ÿæˆçš„æ•™å­¦å†…å®¹çš„**æ•™å­¦å¥å…¨æ€§**å’Œ**æ¦‚å¿µå‡†ç¡®æ€§**ã€‚å®ƒä½¿ç”¨ EduCheck-SFT æ¨¡å‹ï¼Œæ—¨åœ¨å®ç°**â€œå®‰å…¨ä¼˜å…ˆï¼ˆé«˜å¬å›ç‡ï¼‰â€**çš„è®¾è®¡ç›®æ ‡ã€‚")


# --- è¾“å…¥åŒºåŸŸ ---
col_topic, col_answer = st.columns([1, 2])

# é»˜è®¤å®‰å…¨æ¡ˆä¾‹
safe_explanation = "æ•°ç»„æ˜¯ä¸€ç§æ•°æ®ç»“æ„ï¼Œç”¨äºå­˜å‚¨å›ºå®šå¤§å°çš„ã€å…ƒç´ ç±»å‹ç›¸åŒä¸”ä½äºç›¸é‚»å†…å­˜ä½ç½®çš„æœ‰åºé›†åˆã€‚"

with col_topic:
    user_topic = st.text_area(
        "1. æ•™å­¦ä¸»é¢˜ (Topic):",
        "æ•°æ®ç»“æ„ (æ•°ç»„)", 
        height=100
    )

with col_answer:
    ai_answer = st.text_area(
        "2. AI ç”Ÿæˆçš„è§£é‡Š (Explanation):",
        safe_explanation, 
        height=100
    )

# --- é¢„æµ‹æ‰§è¡Œ ---
if st.button("ğŸš¨ è¿è¡Œ EduCheck åˆ†æ", type="primary"):
    if model_real is None:
        st.error("æ¨¡å‹æœªåŠ è½½ã€‚æ— æ³•è¿è¡Œåˆ†æã€‚è¯·æ£€æŸ¥æ§åˆ¶å°/æ—¥å¿—ä¸­çš„é”™è¯¯ä¿¡æ¯ã€‚")
        st.stop()
        
    if not user_topic or not ai_answer:
        st.warning("è¯·åŒæ—¶å¡«å†™æ•™å­¦ä¸»é¢˜å’Œ AI è§£é‡Šæ–‡æœ¬ã€‚")
        st.stop()

    # æ ¼å¼åŒ–è¾“å…¥æ–‡æœ¬
    input_text = f"### Topic:\n{user_topic}\n\n### Explanation:\n{ai_answer}"
    
    # è¿è¡Œé¢„æµ‹
    predicted_id, confidence, probabilities = predict_hallucination(
        input_text, tokenizer_real, model_real
    )
    
    # ä»…åœ¨é¢„æµ‹æˆåŠŸæ—¶ç»§ç»­
    if predicted_id is not None:
        st.markdown("---")
        
        # --- ç»“æœæ˜¾ç¤º ---
        col_res, col_metric = st.columns(2)
        
        predicted_label = LABEL_MAPPING.get(predicted_id)

        with col_res:
            if predicted_id == 1:
                st.error(f"### ç»“æœ: {predicted_label}")
            else:
                st.success(f"### ç»“æœ: {predicted_label}")

        with col_metric:
            st.metric("ç½®ä¿¡åº¦åˆ†æ•° (Confidence)", f"{confidence:.2%}")
            
        st.markdown("#### è¯Šæ–­æŠ¥å‘Š")

        # --- æ˜¾ç¤ºè¯Šæ–­è¯¦æƒ… ---
        if predicted_id == 1:
            st.error(f"**ç¼ºé™·ç±»å‹:** é«˜é£é™©å¹»è§‰")
            st.write(f"**è¯Šæ–­è¯¦æƒ…:** æ¨¡å‹æ ¹æ®å…¶æ ¸å¿ƒåˆ†ç±»æ£€æµ‹åˆ°é«˜é£é™©å¹»è§‰ã€‚**å»ºè®®äººå·¥å®¡æ ¸**ä»¥å¯¹å…·ä½“çš„é”™è¯¯ç±»å‹ï¼ˆäº‹å®æ€§ã€æ¦‚å¿µæ€§æˆ–æ•™å­¦æ³•ç¼ºé™·ï¼‰è¿›è¡Œåˆ†ç±»ã€‚")
                
        else:
            st.info("æ¨¡å‹åˆ¤å®šå†…å®¹å®‰å…¨ã€‚è¯¥è§£é‡Š**æ¦‚å¿µå‡†ç¡®ä¸”æ•™å­¦æ³•ä¸Šåˆç†**ã€‚")

        # --- è¯¦ç»†æ¦‚ç‡åˆ†å¸ƒ ---
        st.markdown("---")
        st.markdown("#### è¯¦ç»†æ¦‚ç‡åˆ†å¸ƒï¼ˆäºŒå…ƒï¼‰")
        
        probs_df = pd.Series(
            probabilities, 
            index=CONFIDENCE_LABELS
        ).sort_values(ascending=False)
        
        st.bar_chart(probs_df)
