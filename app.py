import streamlit as st
import torch
from transformers import AutoTokenizer, AutoModelForSequenceClassification
import numpy as np
import pandas as pd
# ç§»é™¤äº† os æ¨¡å—ï¼Œå› ä¸ºå®ƒä¸å†æ˜¯å¿…éœ€çš„

# ========================================================================
# --- äº‘ç«¯éƒ¨ç½²é…ç½® ---
# ========================================================================
# ğŸš¨ ä½ çš„ Hugging Face ä»“åº“ ID (åŒ…å« model.safetensors, config.json)
MODEL_REPO_ID = "Jasonzeng/EduCheck" 
# ğŸš¨ åˆ†è¯å™¨æ¥æº ID (ä¸ä½ æœ¬åœ°ä»£ç ä¸­çš„ 'distilbert-base-uncased' å¯¹åº”)
TOKENIZER_ID = "distilbert-base-uncased"
# ========================================================================


# --- 1. Label Mapping ---
LABEL_MAPPING = {
    0: "Non-Hallucination (Safe) âœ…",
    1: "Hallucination Detected ğŸš¨"
}
CONFIDENCE_LABELS = ["Non-Hallucination", "Hallucination"]


@st.cache_resource
def load_model_and_tokenizer():
    """
    åŠ è½½æ¨¡å‹å’Œåˆ†è¯å™¨ã€‚åˆ†è¯å™¨ä»å…¬å…± ID åŠ è½½ï¼Œæ¨¡å‹æƒé‡ä»ä½ çš„ HF ä»“åº“ ID åŠ è½½ã€‚
    """
    st.info(f"æ­£åœ¨åŠ è½½åˆ†è¯å™¨ ({TOKENIZER_ID}) å’Œæ¨¡å‹æƒé‡ ({MODEL_REPO_ID})...")
    
    try:
        # 1. åŠ è½½åˆ†è¯å™¨ (ä»å…¬å…±ä»“åº“åŠ è½½ï¼Œä¸éœ€è¦ä½ ä¸Šä¼ åˆ†è¯å™¨æ–‡ä»¶)
        tokenizer = AutoTokenizer.from_pretrained(TOKENIZER_ID)
        
        # 2. åŠ è½½æ¨¡å‹æƒé‡ (ä»ä½ çš„ HF ä»“åº“åŠ è½½å¤§æ–‡ä»¶)
        # æ­¤æ—¶ï¼ŒAutoModel åªéœ€è¦ä½ çš„ä»“åº“ä¸­æœ‰ model.safetensors å’Œ config.json
        model = AutoModelForSequenceClassification.from_pretrained(MODEL_REPO_ID, num_labels=2)
        model.eval()
        
        st.success("âœ… Model Loaded Successfully!")
        return tokenizer, model
    except Exception as e:
        st.error(f"âŒ Error loading EduCheck-SFT model. è¯¦æƒ…: {e}") 
        st.error(f"è¯·æ£€æŸ¥ï¼š1) åˆ†è¯å™¨ ID ({TOKENIZER_ID}) æ˜¯å¦æ‹¼å†™æ­£ç¡®ã€‚2) ä»“åº“ ({MODEL_REPO_ID}) ä¸­æ˜¯å¦åŒ…å« 'model.safetensors' å’Œ 'config.json'ã€‚")
        return None, None

# --- The actual prediction function (ä¿æŒä¸å˜) ---
def predict_hallucination(input_text: str, tokenizer, model):
    """Predicts hallucination using the loaded model."""
    if model and tokenizer:
        inputs = tokenizer(input_text, 
                            padding="max_length", 
                            truncation=True, 
                            max_length=128, 
                            return_tensors="pt")
        
        with torch.no_grad():
            outputs = model(**inputs)
            
        probabilities = torch.softmax(outputs.logits, dim=1).squeeze().numpy()
        predicted_class_id = np.argmax(probabilities).item()
        confidence = probabilities[predicted_class_id].item()
        
        return predicted_class_id, confidence, probabilities
        
    else:
        st.error("Prediction failed: Model not loaded. Please check model files.")
        return None, None, None

# --- Load the model (try real, fall back to failure) ---
tokenizer_real, model_real = load_model_and_tokenizer()

# =======================================================
# --- Streamlit UI Components (ä¿æŒä¸å˜) ---
# =======================================================

st.set_page_config(layout="wide", page_title="EduCheck: AI Content Safety")

st.title("ğŸ›¡ï¸ EduCheck: AI Educational Content Safety Detector")
st.markdown("---")

st.subheader("Beyond Fact-Checking: Detecting Pedagogical & Conceptual Flaws")
st.info("This tool validates the **Pedagogical Soundness** and **Conceptual Accuracy** of AI-generated teaching content. It utilizes the EduCheck-SFT model, trained with a weighted loss function, achieving a **'Safety-First (High Recall)'** design objective.")


# --- Input Area ---
col_topic, col_answer = st.columns([1, 2])

safe_explanation = "An Array is a data structure used to store a fixed-size sequential collection of elements of the same type in adjacent memory locations."

with col_topic:
    user_topic = st.text_area(
        "1. Teaching Topic (Topic):",
        "Data Structure (Array)", 
        height=100
    )

with col_answer:
    ai_answer = st.text_area(
        "2. AI-Generated Explanation (Explanation):",
        safe_explanation, 
        height=100
    )

# --- Prediction Execution ---
if st.button("ğŸš¨ Run EduCheck Analysis", type="primary"):
    if not user_topic or not ai_answer:
        st.warning("Please fill in both the Teaching Topic and the AI Explanation text.")
        st.stop()

    # Format input text
    input_text = f"### Topic:\n{user_topic}\n\n### Explanation:\n{ai_answer}"
    
    # Run Prediction
    predicted_id, confidence, probabilities = predict_hallucination(input_text, tokenizer_real, model_real)
    
    # Only proceed if prediction was successful
    if predicted_id is not None:
        st.markdown("---")
        
        # --- Result Display ---
        col_res, col_metric = st.columns(2)
        
        predicted_label = LABEL_MAPPING.get(predicted_id)

        with col_res:
            if predicted_id == 1:
                st.error(f"### Result: {predicted_label}")
            else:
                st.success(f"### Result: {predicted_label}")

        with col_metric:
            st.metric("Confidence Score (Confidence)", f"{confidence:.2%}")
            
        st.markdown("#### Diagnostic Report")

        # --- Display only general diagnosis ---
        if predicted_id == 1:
            st.error(f"**Flaw Type:** High Risk Hallucination")
            st.write(f"**Diagnosis Details:** The model detected a high-risk hallucination based on its core classification. **Human Review is Recommended** to categorize the specific error type (Factual, Conceptual, or Pedagogical).")
                
        else:
            st.info("Model judges content as safe. This explanation is **conceptually accurate and pedagogically sound** for the target audience.")

        # --- Detailed Probability Distribution ---
        st.markdown("---")
        st.markdown("#### Detailed Probability Distribution (Binary)")
        
        probs_df = pd.Series(
            probabilities, 
            index=CONFIDENCE_LABELS
        ).sort_values(ascending=False)
        
        st.bar_chart(probs_df)
